{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd0bda60-5efe-4991-9320-477276071322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, pdb, sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22545e28-ae29-4298-aa15-68f739dcd022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getrecursionlimit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04caa84f-3dd4-4864-8a99-bc8464c4ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.setrecursionlimit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48db91f2-c89b-4acc-b04c-921de8752d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs = [d for d in os.listdir(os.getcwd()) if os.path.isdir(d) and not d.startswith('.')]\n",
    "len(langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a2bc5c6-76a7-4ca2-a443-c44af4ffdd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(lang):\n",
    "    deriv = pd.read_csv(f'{lang}/{lang}.derivational.v1.tsv',sep='\\t',names=['source_word','target_word','source_pos','target_pos','morpheme','type'])\n",
    "    infl = pd.read_csv(f'{lang}/{lang}.inflectional.v1.tsv',sep='\\t',names=['lemma','inflected_form','morph_feat','morph_seg'])\n",
    "    return deriv,infl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa4af278-9d21-46a6-9ebc-e24b1017b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "deriv,infl = load_data('deu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "960819b5-97df-440e-a875-27e1a0c8defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "deriv.source_word.fillna('null',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f60b3c73-4e8e-461c-bea3-2a72969fec38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_word</th>\n",
       "      <th>target_word</th>\n",
       "      <th>source_pos</th>\n",
       "      <th>target_pos</th>\n",
       "      <th>morpheme</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>axial</td>\n",
       "      <td>abaxial</td>\n",
       "      <td>J</td>\n",
       "      <td>J</td>\n",
       "      <td>ab</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Laut</td>\n",
       "      <td>ablaut</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>ab</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>ese</td>\n",
       "      <td>suffix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liste</td>\n",
       "      <td>listen</td>\n",
       "      <td>N</td>\n",
       "      <td>V</td>\n",
       "      <td>en</td>\n",
       "      <td>suffix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fallen</td>\n",
       "      <td>befallen</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>be</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29376</th>\n",
       "      <td>finden</td>\n",
       "      <td>hereinfinden</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>herein</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29377</th>\n",
       "      <td>finden</td>\n",
       "      <td>hinfinden</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>hin</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29378</th>\n",
       "      <td>Bulgarien</td>\n",
       "      <td>Bulgarier</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>er</td>\n",
       "      <td>suffix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29379</th>\n",
       "      <td>Streit</td>\n",
       "      <td>Streiterei</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>erei</td>\n",
       "      <td>suffix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29380</th>\n",
       "      <td>Osterei</td>\n",
       "      <td>Ostereichen</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>chen</td>\n",
       "      <td>suffix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29381 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source_word   target_word source_pos target_pos morpheme    type\n",
       "0           axial       abaxial          J          J       ab  prefix\n",
       "1            Laut        ablaut          N          N       ab  prefix\n",
       "2           China       Chinese          N          N      ese  suffix\n",
       "3           Liste        listen          N          V       en  suffix\n",
       "4          fallen      befallen          V          V       be  prefix\n",
       "...           ...           ...        ...        ...      ...     ...\n",
       "29376      finden  hereinfinden          V          V   herein  prefix\n",
       "29377      finden     hinfinden          V          V      hin  prefix\n",
       "29378   Bulgarien     Bulgarier          N          N       er  suffix\n",
       "29379      Streit    Streiterei          N          N     erei  suffix\n",
       "29380     Osterei   Ostereichen          N          N     chen  suffix\n",
       "\n",
       "[29381 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27073ab7-264a-4ff4-a19f-ed5c3e882e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_word</th>\n",
       "      <th>target_word</th>\n",
       "      <th>source_pos</th>\n",
       "      <th>target_pos</th>\n",
       "      <th>morpheme</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [source_word, target_word, source_pos, target_pos, morpheme, type]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deriv[deriv.target_word.str.contains('agriculture')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9541711e-f752-4978-9a5c-85545de95586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment(source_word,segmentation=None,typ=None):\n",
    "    # pdb.set_trace()\n",
    "    result = deriv.query(f\"target_word=='{source_word}'\")\n",
    "    if len(result)==0:\n",
    "        return (source_word,)\n",
    "    else:\n",
    "        source_word = result.source_word.values[0]\n",
    "        morpheme = result.morpheme.values[0]\n",
    "        typ = result.type.values[0]\n",
    "        \n",
    "        previous_segment = get_segment(source_word)\n",
    "        \n",
    "        if typ=='prefix':\n",
    "            return morpheme+'#',*previous_segment\n",
    "        elif typ=='suffix':\n",
    "            return *previous_segment,'#'+morpheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3cd8478-c1c2-49b9-8e67-d9b1af0b3aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('agriculture', '#al')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = get_segment('agricultural')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5639dd27-2d6b-4919-bf54-742a3ccf742e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29381/29381 [01:19<00:00, 369.24it/s]\n"
     ]
    }
   ],
   "source": [
    "segments={}\n",
    "for row in tqdm(deriv.iterrows(),total=len(deriv)):\n",
    "    index = row[0]\n",
    "    try:\n",
    "        seg = get_segment(row[1].target_word)\n",
    "        segments[index]=seg\n",
    "    except Exception as e:\n",
    "        segments[index]=e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78570f19-6adb-4680-9672-c1a723288aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "deriv['segments']=pd.Series(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8629a949-93fb-43d4-aaa0-fcfb0b6664e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_word</th>\n",
       "      <th>target_word</th>\n",
       "      <th>source_pos</th>\n",
       "      <th>target_pos</th>\n",
       "      <th>morpheme</th>\n",
       "      <th>type</th>\n",
       "      <th>segments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>axial</td>\n",
       "      <td>abaxial</td>\n",
       "      <td>J</td>\n",
       "      <td>J</td>\n",
       "      <td>ab</td>\n",
       "      <td>prefix</td>\n",
       "      <td>(ab#, axial)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Laut</td>\n",
       "      <td>ablaut</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>ab</td>\n",
       "      <td>prefix</td>\n",
       "      <td>(ab#, Laut)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>ese</td>\n",
       "      <td>suffix</td>\n",
       "      <td>(China, #ese)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liste</td>\n",
       "      <td>listen</td>\n",
       "      <td>N</td>\n",
       "      <td>V</td>\n",
       "      <td>en</td>\n",
       "      <td>suffix</td>\n",
       "      <td>(Liste, #en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fallen</td>\n",
       "      <td>befallen</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>be</td>\n",
       "      <td>prefix</td>\n",
       "      <td>(be#, fallen)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29376</th>\n",
       "      <td>finden</td>\n",
       "      <td>hereinfinden</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>herein</td>\n",
       "      <td>prefix</td>\n",
       "      <td>(herein#, finden)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29377</th>\n",
       "      <td>finden</td>\n",
       "      <td>hinfinden</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>hin</td>\n",
       "      <td>prefix</td>\n",
       "      <td>(hin#, finden)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29378</th>\n",
       "      <td>Bulgarien</td>\n",
       "      <td>Bulgarier</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>er</td>\n",
       "      <td>suffix</td>\n",
       "      <td>(Bulgarien, #er)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29379</th>\n",
       "      <td>Streit</td>\n",
       "      <td>Streiterei</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>erei</td>\n",
       "      <td>suffix</td>\n",
       "      <td>(Streit, #erei)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29380</th>\n",
       "      <td>Osterei</td>\n",
       "      <td>Ostereichen</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>chen</td>\n",
       "      <td>suffix</td>\n",
       "      <td>(Osterei, #chen)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29381 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source_word   target_word source_pos target_pos morpheme    type  \\\n",
       "0           axial       abaxial          J          J       ab  prefix   \n",
       "1            Laut        ablaut          N          N       ab  prefix   \n",
       "2           China       Chinese          N          N      ese  suffix   \n",
       "3           Liste        listen          N          V       en  suffix   \n",
       "4          fallen      befallen          V          V       be  prefix   \n",
       "...           ...           ...        ...        ...      ...     ...   \n",
       "29376      finden  hereinfinden          V          V   herein  prefix   \n",
       "29377      finden     hinfinden          V          V      hin  prefix   \n",
       "29378   Bulgarien     Bulgarier          N          N       er  suffix   \n",
       "29379      Streit    Streiterei          N          N     erei  suffix   \n",
       "29380     Osterei   Ostereichen          N          N     chen  suffix   \n",
       "\n",
       "                segments  \n",
       "0           (ab#, axial)  \n",
       "1            (ab#, Laut)  \n",
       "2          (China, #ese)  \n",
       "3           (Liste, #en)  \n",
       "4          (be#, fallen)  \n",
       "...                  ...  \n",
       "29376  (herein#, finden)  \n",
       "29377     (hin#, finden)  \n",
       "29378   (Bulgarien, #er)  \n",
       "29379    (Streit, #erei)  \n",
       "29380   (Osterei, #chen)  \n",
       "\n",
       "[29381 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33079fbe-7cd3-477a-ab29-550b522f9e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_word</th>\n",
       "      <th>target_word</th>\n",
       "      <th>source_pos</th>\n",
       "      <th>target_pos</th>\n",
       "      <th>morpheme</th>\n",
       "      <th>type</th>\n",
       "      <th>segments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [source_word, target_word, source_pos, target_pos, morpheme, type, segments]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deriv.query(f\"target_word=='finden'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c70bd044-4c6a-4750-af91-6551b735caf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>inflected_form</th>\n",
       "      <th>morph_feat</th>\n",
       "      <th>morph_seg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zufÃ¼gen</td>\n",
       "      <td>zufÃ¼gen</td>\n",
       "      <td>V;NFIN</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zufÃ¼gen</td>\n",
       "      <td>zufÃ¼gend</td>\n",
       "      <td>V;V.PTCP;PRS</td>\n",
       "      <td>zu-|fÃ¼g|-end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zufÃ¼gen</td>\n",
       "      <td>zugefÃ¼gt</td>\n",
       "      <td>V;V.PTCP;PST</td>\n",
       "      <td>zu-|ge-|fÃ¼g|-t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zufÃ¼gen</td>\n",
       "      <td>fÃ¼ge zu</td>\n",
       "      <td>V|IND;PRS;1;SG ADP</td>\n",
       "      <td>fÃ¼g|-e zu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zufÃ¼gen</td>\n",
       "      <td>fÃ¼gen zu</td>\n",
       "      <td>V|IND;PRS;1;PL ADP</td>\n",
       "      <td>fÃ¼g|-en zu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490326</th>\n",
       "      <td>Schifffahrt</td>\n",
       "      <td>Schifffahrten</td>\n",
       "      <td>N|ACC;PL</td>\n",
       "      <td>Schifffahrt|en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490327</th>\n",
       "      <td>Katzenstreu</td>\n",
       "      <td>Katzenstreu</td>\n",
       "      <td>N;NOM;SG;FEM</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490328</th>\n",
       "      <td>Katzenstreu</td>\n",
       "      <td>Katzenstreu</td>\n",
       "      <td>N;GEN;SG;FEM</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490329</th>\n",
       "      <td>Katzenstreu</td>\n",
       "      <td>Katzenstreu</td>\n",
       "      <td>N;DAT;SG;FEM</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490330</th>\n",
       "      <td>Katzenstreu</td>\n",
       "      <td>Katzenstreu</td>\n",
       "      <td>N;ACC;SG;FEM</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490331 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              lemma inflected_form          morph_feat       morph_seg\n",
       "0           zufÃ¼gen        zufÃ¼gen              V;NFIN               -\n",
       "1           zufÃ¼gen       zufÃ¼gend        V;V.PTCP;PRS    zu-|fÃ¼g|-end\n",
       "2           zufÃ¼gen       zugefÃ¼gt        V;V.PTCP;PST  zu-|ge-|fÃ¼g|-t\n",
       "3           zufÃ¼gen        fÃ¼ge zu  V|IND;PRS;1;SG ADP       fÃ¼g|-e zu\n",
       "4           zufÃ¼gen       fÃ¼gen zu  V|IND;PRS;1;PL ADP      fÃ¼g|-en zu\n",
       "...             ...            ...                 ...             ...\n",
       "490326  Schifffahrt  Schifffahrten            N|ACC;PL  Schifffahrt|en\n",
       "490327  Katzenstreu    Katzenstreu        N;NOM;SG;FEM               -\n",
       "490328  Katzenstreu    Katzenstreu        N;GEN;SG;FEM               -\n",
       "490329  Katzenstreu    Katzenstreu        N;DAT;SG;FEM               -\n",
       "490330  Katzenstreu    Katzenstreu        N;ACC;SG;FEM               -\n",
       "\n",
       "[490331 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18315d45-c530-41c0-9025-d9917235ba40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_952526/1434261198.py\", line 1, in <module>\n",
      "    infl.morph_seg.apply(lambda e: e.split('|'))\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/series.py\", line 4771, in apply\n",
      "    return SeriesApply(self, func, convert_dtype, args, kwargs).apply()\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/apply.py\", line 1105, in apply\n",
      "    return self.apply_standard()\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/apply.py\", line 1156, in apply_standard\n",
      "    mapped = lib.map_infer(\n",
      "  File \"pandas/_libs/lib.pyx\", line 2918, in pandas._libs.lib.map_infer\n",
      "  File \"/tmp/ipykernel_952526/1434261198.py\", line 1, in <lambda>\n",
      "    infl.morph_seg.apply(lambda e: e.split('|'))\n",
      "AttributeError: 'float' object has no attribute 'split'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/lexer.py\", line 499, in _process_state\n",
      "    rex = cls._process_regex(tdef[0], rflags, state)\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/lexer.py\", line 427, in _process_regex\n",
      "    regex = regex.get()\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/lexer.py\", line 415, in get\n",
      "    return regex_opt(self.words, prefix=self.prefix, suffix=self.suffix)\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 91, in regex_opt\n",
      "    return prefix + regex_opt_inner(strings, '(') + suffix\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 63, in regex_opt_inner\n",
      "    + regex_opt_inner([s[plen:] for s in strings], '(?:') \\\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/regexopt.py\", line 36, in regex_opt_inner\n",
      "    return open_paren + escape(first) + close_paren\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/re.py\", line 273, in escape\n",
      "    if isinstance(pattern, str):\n",
      "RecursionError: maximum recursion depth exceeded while calling a Python object\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2052, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 155, in _format_traceback_lines\n",
      "    line = stack_line.render(pygmented=has_colors).rstrip('\\n') + '\\n'\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/stack_data/core.py\", line 391, in render\n",
      "    start_line, lines = self.frame_info._pygmented_scope_lines\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/stack_data/core.py\", line 824, in _pygmented_scope_lines\n",
      "    lines = _pygmented_with_ranges(formatter, code, ranges)\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/stack_data/utils.py\", line 154, in _pygmented_with_ranges\n",
      "    class MyLexer(type(get_lexer_by_name(\"python3\"))):\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/lexers/__init__.py\", line 106, in get_lexer_by_name\n",
      "    return _lexer_cache[name](**options)\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/lexer.py\", line 581, in __call__\n",
      "    cls._tokens = cls.process_tokendef('', cls.get_tokendefs())\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/lexer.py\", line 520, in process_tokendef\n",
      "    cls._process_state(tokendefs, processed, state)\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/lexer.py\", line 483, in _process_state\n",
      "    tokens.extend(cls._process_state(unprocessed, processed,\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/lexer.py\", line 483, in _process_state\n",
      "    tokens.extend(cls._process_state(unprocessed, processed,\n",
      "  File \"/home/jabbar/miniconda3/envs/nlp/lib/python3.10/site-packages/pygments/lexer.py\", line 501, in _process_state\n",
      "    raise ValueError(\"uncompilable regex %r in state %r of %r: %s\" %\n",
      "ValueError: uncompilable regex <pygments.lexer.words object at 0x7f9d79ebee30> in state 'builtins' of <class 'pygments.lexers.python.PythonLexer'>: maximum recursion depth exceeded while calling a Python object\n"
     ]
    }
   ],
   "source": [
    "infl.morph_seg.apply(lambda e: e.split('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d677612-9289-49a6-9f84-3bc28c434b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
